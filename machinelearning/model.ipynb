{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = \"mongodb+srv://thurein:yZvltzHCExQyT4Mw@cluster1.gd9wruo.mongodb.net/?retryWrites=true&w=majority\"\n",
    "client = MongoClient(connection_string)\n",
    "db = client['MustreamDatabase']\n",
    "collection = db['tracks']\n",
    "data = collection.find()\n",
    "\n",
    "spotify_songs_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                          object\n",
       "track_id                     object\n",
       "track_name                   object\n",
       "track_artist                 object\n",
       "track_popularity              int64\n",
       "track_album_id               object\n",
       "track_album_name             object\n",
       "track_album_release_date     object\n",
       "playlist_name                object\n",
       "playlist_id                  object\n",
       "playlist_genre               object\n",
       "playlist_subgenre            object\n",
       "danceability                float64\n",
       "energy                      float64\n",
       "key                           int64\n",
       "loudness                    float64\n",
       "mode                          int64\n",
       "speechiness                 float64\n",
       "acousticness                float64\n",
       "instrumentalness            float64\n",
       "liveness                    float64\n",
       "valence                     float64\n",
       "tempo                       float64\n",
       "duration_ms                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_songs_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping for songs\n",
    "genre_to_idx = {genre: idx for idx, genre in enumerate(spotify_songs_df['playlist_subgenre'].unique())}\n",
    "artist_to_idx = {artist: idx for idx, artist in enumerate(spotify_songs_df['track_artist'].unique())}\n",
    "track_to_idx = {track: idx for idx, track in enumerate(spotify_songs_df['track_name'].unique())}\n",
    "idx_to_track = {idx: track for track, idx in track_to_idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dance pop' 'post-teen pop' 'electropop' 'indie poptimism' 'hip hop'\n",
      " 'southern hip hop' 'gangster rap' 'trap' 'album rock' 'classic rock'\n",
      " 'permanent wave' 'hard rock' 'tropical' 'latin pop' 'reggaeton'\n",
      " 'latin hip hop' 'urban contemporary' 'hip pop' 'neo soul' 'electro house'\n",
      " 'big room' 'pop edm' 'progressive electro house']\n"
     ]
    }
   ],
   "source": [
    "print(spotify_songs_df[spotify_songs_df['track_popularity'] > 80]['playlist_subgenre'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Black Eyed Peas' 'MEDUZA' 'Billie Eilish' 'Regard' 'KAROL G'\n",
      " 'Shawn Mendes' 'Maroon 5' 'The Weeknd' 'Juice WRLD' 'Justin Bieber'\n",
      " 'Tones and I' 'Lewis Capaldi' 'J Balvin' 'Selena Gomez' 'Anuel AA'\n",
      " 'Sam Smith' 'Ed Sheeran' 'Harry Styles' 'Travis Scott' 'Rauw Alejandro'\n",
      " 'Post Malone' 'Dua Lipa' 'blackbear' 'Dan + Shay' 'Y2K' 'Camila Cabello'\n",
      " 'Trevor Daniel' 'Tyga' 'Don Toliver' 'DaBaby' 'Future' 'Roddy Ricch'\n",
      " 'Lil Uzi Vert' 'Bad Bunny' 'Dalex' 'Arizona Zervas']\n"
     ]
    }
   ],
   "source": [
    "print(spotify_songs_df[spotify_songs_df['track_popularity'] > 90]['track_artist'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32833\n",
      "10693\n",
      "24\n",
      "['dance pop', 'post-teen pop', 'electropop', 'indie poptimism', 'hip hop', 'southern hip hop', 'gangster rap', 'trap', 'album rock', 'classic rock', 'permanent wave', 'hard rock', 'tropical', 'latin pop', 'reggaeton', 'latin hip hop', 'urban contemporary', 'hip pop', 'new jack swing', 'neo soul', 'electro house', 'big room', 'pop edm', 'progressive electro house']\n"
     ]
    }
   ],
   "source": [
    "print(len(spotify_songs_df.index))\n",
    "print(spotify_songs_df['track_artist'].nunique())\n",
    "print(spotify_songs_df['playlist_subgenre'].nunique())\n",
    "print(list(spotify_songs_df['playlist_subgenre'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SongRecommender(nn.Module):\n",
    "    def __init__(self, num_songs, num_genres, num_artists, embedding_size):\n",
    "        super(SongRecommender, self).__init__()\n",
    "        self.song_embedding = nn.Embedding(num_songs, embedding_size)\n",
    "        self.genre_embedding = nn.Embedding(num_genres, embedding_size)\n",
    "        self.artist_embedding = nn.Embedding(num_artists, embedding_size)\n",
    "        # The linear layer should match the combined size of all embeddings\n",
    "        self.fc = nn.Linear(embedding_size * 3, 1)\n",
    "\n",
    "    def forward(self, genre_indices, artist_indices, song_indices):\n",
    "        genre_embed = self.genre_embedding(genre_indices)\n",
    "        artist_embed = self.artist_embedding(artist_indices)\n",
    "        song_embed = self.song_embedding(song_indices)\n",
    "\n",
    "        # Ensure all tensors are 2D\n",
    "        if genre_embed.ndim == 1:\n",
    "            genre_embed = genre_embed.unsqueeze(0)\n",
    "        if artist_embed.ndim == 1:\n",
    "            artist_embed = artist_embed.unsqueeze(0)\n",
    "        if song_embed.ndim == 1:\n",
    "            song_embed = song_embed.unsqueeze(0)\n",
    "\n",
    "        # Concatenate embeddings along the feature dimension\n",
    "        combined = torch.cat((genre_embed, artist_embed, song_embed), dim=1)\n",
    "        scores = self.fc(combined).squeeze()\n",
    "        return scores\n",
    "\n",
    "num_songs = len(track_to_idx)\n",
    "num_genres = len(genre_to_idx)\n",
    "num_artists = len(artist_to_idx)\n",
    "embedding_size = 50 \n",
    "\n",
    "model = SongRecommender(num_songs, num_genres, num_artists, embedding_size)\n",
    "\n",
    "# Train the model (You should train it with your actual data)\n",
    "\n",
    "# Save the entire model (including architecture and weights)\n",
    "model_filename = 'mustream-recommender.pth'\n",
    "torch.save(model, model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_songs(model, user_like_genres, user_like_artists, top_k=10):\n",
    "    # Convert user preferences to indices\n",
    "    genre_indices = torch.tensor([genre_to_idx.get(genre, -1) for genre in user_like_genres if genre in genre_to_idx], dtype=torch.long)\n",
    "    artist_indices = torch.tensor([artist_to_idx.get(artist, -1) for artist in user_like_artists if artist in artist_to_idx], dtype=torch.long)\n",
    "\n",
    "    if len(genre_indices) == 0 or len(artist_indices) == 0:\n",
    "        return []\n",
    "\n",
    "    # Calculate the average embedding for genres and artists\n",
    "    avg_genre_embedding = model.genre_embedding(genre_indices).mean(dim=0, keepdim=True)\n",
    "    avg_artist_embedding = model.artist_embedding(artist_indices).mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Prepare song embeddings\n",
    "    song_indices = torch.arange(len(track_to_idx), dtype=torch.long)\n",
    "    song_embeddings = model.song_embedding(song_indices)\n",
    "\n",
    "    # Repeat genre and artist embeddings to match the number of songs\n",
    "    repeated_genre_embedding = avg_genre_embedding.repeat(len(track_to_idx), 1)\n",
    "    repeated_artist_embedding = avg_artist_embedding.repeat(len(track_to_idx), 1)\n",
    "\n",
    "    # Concatenate embeddings\n",
    "    combined_embeddings = torch.cat((repeated_genre_embedding, repeated_artist_embedding, song_embeddings), dim=1)\n",
    "\n",
    "    # Get song scores from the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        song_scores = model.fc(combined_embeddings).squeeze()\n",
    "\n",
    "    # Get the top k song indices\n",
    "    _, top_song_indices = torch.topk(song_scores, top_k, largest=True)\n",
    "    top_song_indices = top_song_indices.cpu().numpy()\n",
    "\n",
    "    # Map indices to song names\n",
    "    recommended_songs = [idx_to_track[idx] for idx in top_song_indices]\n",
    "    return recommended_songs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Songs: ['Tommy Gun', 'How We Move (feat. King L)', 'Conga', 'Méditerranée', 'All Night Long - Zakkov Remix', 'One Wine (feat. Major Lazer)', 'Until', 'Cataclysm جائحة', 'Psycho Killer - 2005 Remaster', 'Waverunners']\n"
     ]
    }
   ],
   "source": [
    "num_songs = len(track_to_idx)\n",
    "num_genres = len(genre_to_idx)\n",
    "num_artists = len(artist_to_idx)\n",
    "embedding_size = 50  # Example size, adjust as needed\n",
    "\n",
    "model = SongRecommender(num_songs, num_genres, num_artists, embedding_size)\n",
    "\n",
    "# Example user preferences\n",
    "user_like_genres = ['electropop', 'hip hop']  # Example genres\n",
    "user_like_artists = ['Ed Sheeran', 'The Beatles']  # Example artists\n",
    "\n",
    "# Get recommendations (assuming the model is already trained)\n",
    "recommended_songs = recommend_songs(model, user_like_genres, user_like_artists)\n",
    "print(\"Recommended Songs:\", recommended_songs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mustream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
